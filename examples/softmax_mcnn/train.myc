@import "examples/softmax_mcnn/model.myc"

function main() {
	:images [][28][28]uint8 = read_dataset_image("./examples/softmax_mcnn/training_set/train-images-idx3-ubyte");
	:labels []     uint8 = read_dataset_label("./examples/softmax_mcnn/training_set/train-labels-idx1-ubyte");
	
	printf("%llx\n".data, images.len);

	// cast image set to f32 range [-1.0, 1.0]
	:image_set [][784]f32 = allocate(28*28*images.len*4);
	for(:i uint32 = 0; i < [uint32]image_set.len; i++) {
		for(:r uint32 = 0; r < 28; r++) {
			for(:c uint32 = 0; c < 28; c++) {
				:pixel uint8 = images[i][r][c];
				if pixel > 0 {
					image_set[i][r * 28 + c] = [f32]pixel / 127.5 - 1.0;
				}
			}
		}
	}
	
	// cast label set to binary vector (still f32 because math)
	:label_set [][10]f32 = allocate(labels.len*4*10);
	for(:i uint32 = 0; i < [uint32]label_set.len; i++) {
		:answer uint8 = labels[i];
		label_set[i][answer] = 1.0;	
	}

	
	:neural_network [][]Neuron = nn();
	for(:i int32 = 0; i < [int32]neural_network.len; i++) {
		printf("layers[%u]: %u\n".data, i, neural_network[i].len);
	}

	// ** initialize weights
	:xavier f32 = 0.05;
	srand(time(0));
	{
		:l int32 = 0;
		for(:i int32 = 0; i < [int32]neural_network[l].len; i++) {
			for(:j int32 = 0; j < [int32]neural_network[l][i].weights.len; j++) {
				neural_network[l][i].weights[j] = -xavier + ([f32]rand() / 2147483647.0) * (xavier + xavier);
			}
			neural_network[l][i].bias = -xavier + ([f32]rand() / 2147483647.0) * (xavier + xavier);
		}
	}
	{
		:l int32 = 1;
		for(:i int32 = 0; i < [int32]neural_network[l].len; i++) {
			for(:j int32 = 0; j < [int32]neural_network[l][i].weights.len; j++) {
				neural_network[l][i].weights[j] = -xavier + ([f32]rand() / 2147483647.0) * (xavier + xavier);
			}
			neural_network[l][i].bias = -xavier + ([f32]rand() / 2147483647.0) * (xavier + xavier);
		}
	}

				for(:n int32 = 0; n < [int32]neural_network[0].len; n++) {
					printf("weights:\n".data);
					for(:r uint32 = 0; r < 28; r++) {
						for(:c uint32 = 0; c < 28; c++) {
							printf("%f ".data, [f64]neural_network[0][n].weights[r * 28 + c]);
						}
						printf("\n".data);
					}

					printf("bias: %f\n".data, [f64]neural_network[0][n].bias);
				}


				for(:n int32 = 0; n < [int32]neural_network[1].len; n++) {
					printf("weights:\n".data);
					for(:r uint32 = 0; r < 800; r++) {
						printf("%f ".data, [f64]neural_network[1][n].weights[r]);
					}
					putchar('\n');

					printf("bias: %f\n".data, [f64]neural_network[1][n].bias);
				}


	:f_out ForwardOut = ForwardOut{
		allocate(2 * 16),
		allocate(2 * 16),
	};

	f_out.a[0] = allocate(800 * 4);
	f_out.a[1] = allocate(10 * 4);
	f_out.z[0] = allocate(800 * 4);
	f_out.z[1] = allocate(10 * 4);
	
	for(:example uint32 = 0; example < [uint32]image_set.len; example++) {
		:i uint32 = example; 

		/*
		printf("input:\n".data);
		for(:r uint32 = 0; r < 28; r++) {
			for(:c uint32 = 0; c < 28; c++) {
				printf("%f ".data, [f64]image_set[i][r * 28 + c]);
			}
			printf("\n".data);
		}
		*/


		printf("example #%llu\n".data, i);
		forward(neural_network, image_set[i], f_out);
		back(neural_network, image_set[i], f_out.a, label_set[i], 0.001);
		
		:probability_distribution []f32 = f_out.a[1];
		for(:n int32 = 0; n < [int32]probability_distribution.len; n++) {
			printf("probability[%u]: %f; label[%u]: %f\n".data, n, [f64]probability_distribution[n], n, [f64]label_set[i][n]);
		}
		printf("loss: %f\n".data, [f64]loss(probability_distribution, label_set[i]));
	}
	
	// save weights and biases to file
	save_model("examples/softmax_mcnn/saved_models/model_checkpoint.bin", neural_network);
}
